{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "575546f3-085c-4a5c-a0e7-6f928ca6c629",
   "metadata": {},
   "source": [
    "# 1. Notebook Introduction\n",
    "This notebook provides a complete pipeline to train and evaluate a multi-task (depth prediction + semantic segmentation) model by applying knowledge distillation.\n",
    "The student's architecture is a Unet with a ResNet18 backbone and the teacher will be one of the biggest Depth Anything V3 model (DA3NESTED-GIANT-LARGE).\n",
    "The training stage is tracked with MLFlow and the best set of hyperparameters are found by an Optuna study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890800b3-49cb-415b-86ba-fce6f22e1019",
   "metadata": {},
   "source": [
    "# 2. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166ea1fd-e8d7-493b-9fa8-f85f14100e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import segmentation_models_pytorch as smp\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from collections import defaultdict\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import optuna\n",
    "import optuna.visualization as viz\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b372cb9-5943-497f-92f8-f6a40be48445",
   "metadata": {},
   "source": [
    "# 3. Classes and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c02342-5781-42fa-a16a-ef0736491e0a",
   "metadata": {},
   "source": [
    "## 3.1 Dataset Class\n",
    "Custom dataset class. It implements manual HorizontalFlip and ColorJitter transformations, so they can be applied not only to the input images but also to the Teacher's depth maps and to the ground truth segmentation masks (only HorizontalFlip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ce03c7-d877-4f3b-bc0a-fef521902d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthDistillationDataset(Dataset):\n",
    "    \"\"\"Optimized dataset that loads pre-processed numpy masks.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, depth_dir, seg_dir, num_classes, is_train=False, prob=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.seg_dir = seg_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.is_train = is_train\n",
    "        self.prob = prob if prob is not None else {'horizontal_flip': 0.5, 'color_jitter': 0.5}\n",
    "        \n",
    "        self.images = sorted([f for f in os.listdir(img_dir) if f.endswith('.png')])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        base_name = img_name.replace('.png', '')\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(os.path.join(self.img_dir, img_name)).convert('RGB')\n",
    "        \n",
    "        # Load depth\n",
    "        teacher_depth = np.load(os.path.join(self.depth_dir, f\"{base_name}.npy\"))\n",
    "\n",
    "        # Load pre-processed segmentation mask (already class IDs!)\n",
    "        seg_mask = np.load(os.path.join(self.seg_dir, f\"{base_name}.npy\"))\n",
    "        \n",
    "        # Augmentations\n",
    "        if self.is_train:\n",
    "            if torch.rand(1).item() < self.prob['horizontal_flip']:\n",
    "                image = TF.hflip(image)\n",
    "                teacher_depth = np.fliplr(teacher_depth).copy()\n",
    "                seg_mask = np.fliplr(seg_mask).copy()\n",
    "            \n",
    "            if torch.rand(1).item() < self.prob['color_jitter']:\n",
    "                image = T.ColorJitter(brightness=0.25, contrast=0.25)(image)\n",
    "        \n",
    "        # To tensors\n",
    "        image = TF.to_tensor(image)\n",
    "        image = TF.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        teacher_depth = torch.from_numpy(teacher_depth).float()\n",
    "        seg_mask = torch.from_numpy(seg_mask.copy()).long()\n",
    "        \n",
    "        return image, teacher_depth, seg_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a7b80-f9c7-4b89-8037-84cecd8f49fa",
   "metadata": {},
   "source": [
    "## 3.2 Data Module Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebe3249-b1d6-4914-adb5-6dcf65c5df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 train_img_dir, train_depth_dir, train_seg_dir,\n",
    "                 val_img_dir, val_depth_dir, val_seg_dir,\n",
    "                 test_img_dir, test_depth_dir, test_seg_dir,\n",
    "                 num_classes=32,\n",
    "                 batch_size=4, \n",
    "                 num_workers=2,\n",
    "                 prob=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            train_img_dir, train_depth_dir, train_seg_dir: Training data directories\n",
    "            val_img_dir, val_depth_dir, val_seg_dir: Validation data directories\n",
    "            test_img_dir, test_depth_dir, test_seg_dir: Test data directories\n",
    "            batch_size: Batch size for dataloaders\n",
    "            num_workers: Number of workers for dataloaders\n",
    "            prob: Dictionary with augmentation probabilities\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.train_depth_dir = train_depth_dir\n",
    "        self.train_seg_dir = train_seg_dir\n",
    "        self.val_img_dir = val_img_dir\n",
    "        self.val_depth_dir = val_depth_dir\n",
    "        self.val_seg_dir = val_seg_dir\n",
    "        self.test_img_dir = test_img_dir\n",
    "        self.test_depth_dir = test_depth_dir\n",
    "        self.test_seg_dir = test_seg_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.prob = prob if prob is not None else {'horizontal_flip': 0.5, 'color_jitter': 0.5}\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        if stage == 'fit' or stage is None:\n",
    "            self.train_dataset = DepthDistillationDataset(\n",
    "                img_dir=self.train_img_dir,\n",
    "                depth_dir=self.train_depth_dir,\n",
    "                seg_dir=self.train_seg_dir,\n",
    "                num_classes=self.num_classes,\n",
    "                is_train=True,\n",
    "                prob=self.prob\n",
    "            )\n",
    "            self.val_dataset = DepthDistillationDataset(\n",
    "                img_dir=self.val_img_dir,\n",
    "                depth_dir=self.val_depth_dir,\n",
    "                seg_dir=self.val_seg_dir,\n",
    "                num_classes=self.num_classes,\n",
    "                is_train=False\n",
    "            )\n",
    "        \n",
    "        if stage == 'test' or stage is None:\n",
    "            self.test_dataset = DepthDistillationDataset(\n",
    "                img_dir=self.test_img_dir,\n",
    "                depth_dir=self.test_depth_dir,\n",
    "                seg_dir=self.test_seg_dir,\n",
    "                num_classes=self.num_classes,\n",
    "                is_train=False\n",
    "            )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if self.num_workers > 0 else False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a8e2a8-10eb-454c-98ba-97744e7242b3",
   "metadata": {},
   "source": [
    "## 3.3 Depth + Segmentation Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca6afd-221a-4fcf-987d-86de35252d14",
   "metadata": {},
   "source": [
    "Loss function that basically aggregates the loss used for depth prediction (MSE loss) and the loss used for semantic segmentation (cross-entropy loss). Instead of just adding both losses or weighting them by manually selected values, we used the implementation suggested by Alex Kendall and its collegues (https://arxiv.org/pdf/1705.07115), where the actual weights of the separate loss functions are just another set of learnable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e80773f-a525-4595-ac08-0ce655e75c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthSegMultiTaskLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task loss with learnable uncertainty weighting.\n",
    "    Based on \"Multi-Task Learning Using Uncertainty to Weigh Losses\" (Kendall et al., 2018)\n",
    "    \"\"\"\n",
    "    def __init__(self, init_log_var_depth=0.0, init_log_var_seg=0.0):\n",
    "        super().__init__()\n",
    "        self.log_var_depth = nn.Parameter(torch.tensor(init_log_var_depth))\n",
    "        self.log_var_seg = nn.Parameter(torch.tensor(init_log_var_seg))\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def forward(self, depth_pred, depth_target, seg_pred, seg_target):\n",
    "        # Ensure correct shapes\n",
    "        if depth_pred.dim() == 4:\n",
    "            depth_pred = depth_pred.squeeze(1)\n",
    "        \n",
    "        # Task losses\n",
    "        depth_loss = self.mse_loss(depth_pred, depth_target)\n",
    "        seg_loss = self.ce_loss(seg_pred, seg_target)\n",
    "        \n",
    "        # Uncertainty weighting\n",
    "        # precision = 1/σ², using log_var = log(σ²) for stability\n",
    "        precision_depth = torch.exp(-self.log_var_depth)\n",
    "        precision_seg = torch.exp(-self.log_var_seg)\n",
    "        \n",
    "        weighted_depth = 0.5 * precision_depth * depth_loss + 0.5 * self.log_var_depth\n",
    "        weighted_seg = 0.5 * precision_seg * seg_loss + 0.5 * self.log_var_seg\n",
    "        \n",
    "        total_loss = weighted_depth + weighted_seg\n",
    "        \n",
    "        # Return individual losses for logging\n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'depth_loss': depth_loss,\n",
    "            'seg_loss': seg_loss,\n",
    "            'weight_depth': precision_depth.detach(),\n",
    "            'weight_seg': precision_seg.detach()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b52f3-8981-44e9-ad86-c6b428ce8df7",
   "metadata": {},
   "source": [
    "## 3.4 Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4857ec-9c49-4dec-8d22-78071c2bdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthSegDistillationModule(pl.LightningModule):\n",
    "    def __init__(self, student_model, lr=3e-4, weight_decay=0.0):\n",
    "        super().__init__()\n",
    "        self.student = student_model\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        # Multi-task loss with uncertainty weighting\n",
    "        self.loss_fn = DepthSegMultiTaskLoss()\n",
    "        \n",
    "        self.save_hyperparameters(ignore=['student_model'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.student(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, teacher_depth, seg_mask = batch\n",
    "        \n",
    "        # Get predictions\n",
    "        depth_pred, seg_pred = self(images)\n",
    "        \n",
    "        # Calculate multi-task loss\n",
    "        loss_dict = self.loss_fn(depth_pred, teacher_depth, seg_pred, seg_mask)\n",
    "        \n",
    "        # Log all metrics\n",
    "        self.log('train_total_loss', loss_dict['total_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('train_depth_loss', loss_dict['depth_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('train_seg_loss', loss_dict['seg_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('train_weight_depth', loss_dict['weight_depth'], on_step=False, on_epoch=True)\n",
    "        self.log('train_weight_seg', loss_dict['weight_seg'], on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss_dict['total_loss']\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, teacher_depth, seg_mask = batch\n",
    "        \n",
    "        depth_pred, seg_pred = self(images)\n",
    "        loss_dict = self.loss_fn(depth_pred, teacher_depth, seg_pred, seg_mask)\n",
    "        \n",
    "        self.log('val_total_loss', loss_dict['total_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('val_depth_loss', loss_dict['depth_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('val_seg_loss', loss_dict['seg_loss'], on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss_dict['total_loss']\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, teacher_depth, seg_mask = batch\n",
    "        \n",
    "        depth_pred, seg_pred = self(images)\n",
    "        loss_dict = self.loss_fn(depth_pred, teacher_depth, seg_pred, seg_mask)\n",
    "        \n",
    "        self.log('test_total_loss', loss_dict['total_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('test_depth_loss', loss_dict['depth_loss'], on_step=False, on_epoch=True)\n",
    "        self.log('test_seg_loss', loss_dict['seg_loss'], on_step=False, on_epoch=True)\n",
    "        \n",
    "        return loss_dict['total_loss']\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),  # Includes loss function parameters!\n",
    "            lr=self.lr,\n",
    "            weight_decay=self.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=20\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_total_loss'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe33962-e308-4da1-9775-e261e27a7a11",
   "metadata": {},
   "source": [
    "## 3.5 Multi-Task Unet\n",
    "Extended implementation of the SMP Unet class, where replace the original segmentation head with a pair of heads, one for each of the tasks (depth prediction and semantic segmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e81f833d-3594-4eb7-9dfc-5f971fcefa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskUnet(nn.Module):\n",
    "    def __init__(self, num_classes, encoder_name='resnet18', encoder_weights='imagenet'):\n",
    "        super().__init__()\n",
    "        base = smp.Unet(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            in_channels=3,\n",
    "            classes=1,\n",
    "            activation=None\n",
    "        )\n",
    "        self.encoder = base.encoder\n",
    "        self.decoder = base.decoder\n",
    "        \n",
    "        decoder_out_channels = base.segmentation_head[0].in_channels\n",
    "        \n",
    "        # Two heads\n",
    "        self.depth_head = nn.Conv2d(decoder_out_channels, 1, kernel_size=1)\n",
    "        self.seg_head = nn.Conv2d(decoder_out_channels, num_classes, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feats = self.encoder(x)\n",
    "        dec = self.decoder(feats)\n",
    "        \n",
    "        depth = self.depth_head(dec)\n",
    "        seg = self.seg_head(dec)\n",
    "        \n",
    "        return depth, seg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b830febf-26d9-4454-b539-0f7b9cc1f33d",
   "metadata": {},
   "source": [
    "# 4. Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e7c116f-739f-46c2-88b6-68dbd6d4529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 369\n",
      "Validation samples: 100\n",
      "Test samples: 232\n",
      "\n",
      "Image Size: torch.Size([3, 720, 960])\n",
      "Depth Map Size: torch.Size([720, 960])\n",
      "Segmentation Mask Size: torch.Size([720, 960])\n"
     ]
    }
   ],
   "source": [
    "# Define your paths\n",
    "TRAIN_IMG_DIR = '../CamVid/train/'\n",
    "TRAIN_DEPTH_DIR = '../CamVid/train_labels/train_depths/'\n",
    "TRAIN_SEG_DIR = '../CamVid/train_labels/train_seg_npy/'\n",
    "VAL_IMG_DIR = '../CamVid/val/'\n",
    "VAL_DEPTH_DIR = '../CamVid/val_labels/val_depths/'\n",
    "VAL_SEG_DIR = '../CamVid/val_labels/val_seg_npy/'\n",
    "TEST_IMG_DIR = '../CamVid/test/'\n",
    "TEST_DEPTH_DIR = '../CamVid/test_labels/test_depths/'\n",
    "TEST_SEG_DIR = '../CamVid/test_labels/test_seg_npy/'\n",
    "CLASS_DICT_PATH = '../CamVid/class_dict.csv'\n",
    "\n",
    "# Define augmentation probabilities\n",
    "prob = {\n",
    "    'horizontal_flip': 0.5,\n",
    "    'color_jitter': 0.3\n",
    "}\n",
    "\n",
    "# Create DataModule\n",
    "data_module = DataModule(\n",
    "    train_img_dir=TRAIN_IMG_DIR,\n",
    "    train_depth_dir=TRAIN_DEPTH_DIR,\n",
    "    train_seg_dir=TRAIN_SEG_DIR,\n",
    "    val_img_dir=VAL_IMG_DIR,\n",
    "    val_depth_dir=VAL_DEPTH_DIR,\n",
    "    val_seg_dir=VAL_SEG_DIR,\n",
    "    test_img_dir=TEST_IMG_DIR,\n",
    "    test_depth_dir=TEST_DEPTH_DIR,\n",
    "    test_seg_dir=TEST_SEG_DIR,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    prob=prob\n",
    ")\n",
    "\n",
    "# Test it\n",
    "data_module.setup()\n",
    "print(f\"Training samples: {len(data_module.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(data_module.val_dataset)}\")\n",
    "print(f\"Test samples: {len(data_module.test_dataset)}\")\n",
    "\n",
    "sample_img, sample_depth, sample_mask = data_module.train_dataset[0]\n",
    "print(f\"\\nImage Size: {sample_img.shape}\")\n",
    "print(f\"Depth Map Size: {sample_depth.shape}\")\n",
    "print(f\"Segmentation Mask Size: {sample_mask.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f99324-cb27-47b1-95cf-71035c49f452",
   "metadata": {},
   "source": [
    "All shapes are 720x960, so the dataset is correctly loading the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536207a-1c5d-415b-9efb-5022534db99f",
   "metadata": {},
   "source": [
    "# 5. Training Pipeline\n",
    "We will start by setting up MLFlow configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb905cb4-4479-4fe4-9f81-c69b472b73ee",
   "metadata": {},
   "source": [
    "## 5.1 MLFlow URI and Experiment Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42919fde-f0cd-413e-a78a-db59c9f16fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow tracking URI: mlruns\n",
      "Experiment: depth_distillation_and_semantic_segmentation_optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alumno/Desktop/datos/Computer Vision/depth-anything-3/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n"
     ]
    }
   ],
   "source": [
    "# Set tracking URI\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "\n",
    "# Set experiment name\n",
    "EXPERIMENT_NAME = \"depth_distillation_and_semantic_segmentation_optimization\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Experiment: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d085471-a2fe-4bd3-975b-55a1cee8fdfb",
   "metadata": {},
   "source": [
    "## 5.2 Optuna Objective Function\n",
    "Optuna objective function that defines the following key components:\n",
    "- Hyperparameter Space\n",
    "- Callbacks\n",
    "- Logged Metrics and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41a34431-3a10-499e-8fdd-616767b0f159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization.\n",
    "    Trains depth distillation model and logs to MLflow.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Suggest hyperparameters\n",
    "    params = {\n",
    "        \n",
    "        # Training parameters\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 24, 32]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 5e-5, 1e-3),\n",
    "        'num_epochs': trial.suggest_int('num_epochs', 100, 200),\n",
    "        \n",
    "        # Augmentation probabilities\n",
    "        'prob_horizontal_flip': trial.suggest_float('prob_horizontal_flip', 0.0, 0.7),\n",
    "        'prob_color_jitter': trial.suggest_float('prob_color_jitter', 0.0, 0.7),\n",
    "        \n",
    "        # Optimizer parameters\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-3),\n",
    "        \n",
    "        # Fixed parameters\n",
    "        'encoder_name': 'resnet18',\n",
    "        'encoder_weights': 'imagenet',\n",
    "        'num_workers': 2,\n",
    "        'gradient_clip_val': 1.0,\n",
    "    }\n",
    "    \n",
    "    # Start MLflow run (nested under parent run)\n",
    "    with mlflow.start_run(nested=True, run_name=f\"trial_{trial.number}\"):\n",
    "        \n",
    "        # Log all hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"trial_number\", trial.number)\n",
    "        \n",
    "        # Create augmentation probabilities dict\n",
    "        prob = {\n",
    "            'horizontal_flip': params['prob_horizontal_flip'],\n",
    "            'color_jitter': params['prob_color_jitter']\n",
    "        }\n",
    "        \n",
    "        # Create data module\n",
    "        data_module = DataModule(\n",
    "            train_img_dir=TRAIN_IMG_DIR,\n",
    "            train_depth_dir=TRAIN_DEPTH_DIR,\n",
    "            train_seg_dir=TRAIN_SEG_DIR,\n",
    "            val_img_dir=VAL_IMG_DIR,\n",
    "            val_depth_dir=VAL_DEPTH_DIR,\n",
    "            val_seg_dir=VAL_SEG_DIR,\n",
    "            test_img_dir=TEST_IMG_DIR,\n",
    "            test_depth_dir=TEST_DEPTH_DIR,\n",
    "            test_seg_dir=TEST_SEG_DIR,\n",
    "            batch_size=params['batch_size'],\n",
    "            num_workers=params['num_workers'],\n",
    "            prob=prob\n",
    "        )\n",
    "        data_module.setup()\n",
    "        \n",
    "        # Create student model\n",
    "        student = MultiTaskUnet(\n",
    "            num_classes=data_module.train_dataset.num_classes,\n",
    "            encoder_name=params['encoder_name'],\n",
    "            encoder_weights=params['encoder_weights'],\n",
    "        )\n",
    "        \n",
    "        num_params = sum(p.numel() for p in student.parameters())\n",
    "        mlflow.log_param(\"model_parameters\", num_params)\n",
    "        \n",
    "        # Create Lightning module\n",
    "        lightning_module = DepthSegDistillationModule(\n",
    "            student_model=student,\n",
    "            lr=params['learning_rate'],\n",
    "            weight_decay=params['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # Setup MLflow logger for this trial\n",
    "        mlflow_logger = MLFlowLogger(\n",
    "            experiment_name=EXPERIMENT_NAME,\n",
    "            run_id=mlflow.active_run().info.run_id\n",
    "        )\n",
    "        \n",
    "        # Setup callbacks\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            monitor='val_total_loss',\n",
    "            mode='min',\n",
    "            filename=f'trial_{trial.number}_best',\n",
    "            save_top_k=1,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_total_loss',\n",
    "            patience=15,\n",
    "            mode='min',\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Optuna pruning callback\n",
    "        pruning_callback = PyTorchLightningPruningCallback(trial, monitor=\"val_total_loss\")\n",
    "        \n",
    "        # Create trainer\n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=params['num_epochs'],\n",
    "            logger=mlflow_logger,\n",
    "            callbacks=[checkpoint_callback, early_stopping, pruning_callback],\n",
    "            accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "            devices=1,\n",
    "            gradient_clip_val=params['gradient_clip_val'],\n",
    "            log_every_n_steps=10,\n",
    "            enable_progress_bar=False,\n",
    "            enable_model_summary=False\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        try:\n",
    "            trainer.fit(lightning_module, data_module)\n",
    "            \n",
    "            # FIXED: Get best validation loss properly with proper error handling\n",
    "            if checkpoint_callback.best_model_score is not None:\n",
    "                best_val_loss = float(checkpoint_callback.best_model_score)\n",
    "            else:\n",
    "                # Fallback: get from logged metrics\n",
    "                best_val_loss = float(trainer.callback_metrics.get('val_total_loss', float('inf')))\n",
    "            \n",
    "            # Log best metrics\n",
    "            mlflow.log_metric(\"best_val_total_loss\", best_val_loss)\n",
    "            mlflow.log_metric(\"epochs_trained\", trainer.current_epoch)\n",
    "            \n",
    "            # Evaluate on test set\n",
    "            test_results = trainer.test(\n",
    "                lightning_module, \n",
    "                data_module, \n",
    "                ckpt_path=checkpoint_callback.best_model_path\n",
    "            )\n",
    "            \n",
    "            if test_results:\n",
    "                test_loss = test_results[0].get('test_total_loss', None)\n",
    "                if test_loss:\n",
    "                    mlflow.log_metric(\"test_total_loss\", test_loss)\n",
    "            \n",
    "            # Log model artifact\n",
    "            mlflow.pytorch.log_model(student, \"model\")\n",
    "            \n",
    "            # Log checkpoint (only if path exists)\n",
    "            if checkpoint_callback.best_model_path:\n",
    "                mlflow.log_artifact(checkpoint_callback.best_model_path, \"checkpoints\")\n",
    "            \n",
    "            print(f\"Trial {trial.number}: val_total_loss={best_val_loss:.4f}, \"\n",
    "                  f\"epochs={trainer.current_epoch}\")\n",
    "            \n",
    "            return best_val_loss\n",
    "            \n",
    "        except optuna.TrialPruned:\n",
    "            print(f\"Trial {trial.number} pruned\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Trial {trial.number} failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # Print full traceback for debugging\n",
    "            mlflow.log_param(\"status\", \"failed\")\n",
    "            mlflow.log_param(\"error\", str(e))\n",
    "            return float('inf')\n",
    "        finally:\n",
    "            # CRITICAL: Clean up resources after each trial\n",
    "            print(f\"Cleaning up Trial {trial.number}...\")\n",
    "            \n",
    "            # Delete objects\n",
    "            if 'trainer' in locals():\n",
    "                del trainer\n",
    "            if 'lightning_module' in locals():\n",
    "                del lightning_module\n",
    "            if 'student' in locals():\n",
    "                del student\n",
    "            if 'data_module' in locals():\n",
    "                del data_module\n",
    "            \n",
    "            # Force garbage collection\n",
    "            gc.collect()\n",
    "            \n",
    "            # Clear CUDA cache\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            print(f\"Trial {trial.number} cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa488dfe-0b3a-4591-834b-5757ce82af39",
   "metadata": {},
   "source": [
    "## 5.3 Launch Optuna Study\n",
    "Here we will launch the actual training pipeline. We select a total number of trials (training runs) of 50 and set the sampling algorithm to Tree-structured Parzen Estimator (TPE), which will be the responsible for perform an intelligent search along the hyperparameter space. The Median Pruner will be on charge of stopping bad performing runs so we don't end up wasting too much time on this optimization study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f0cda5-cf4d-4bc6-b809-196353bfc606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "[I 2026-01-09 18:50:06,472] Using an existing study with name 'depth_distillation_and_semantic_segmentation_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optuna optimization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ec54f305314dff9eded77e7cbf969c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alumno/Desktop/datos/Computer Vision/depth-anything-3/.venv/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/utils.py:178: FutureWarning: The filesystem tracking backend (e.g., './mlruns') will be deprecated in February 2026. Consider transitioning to a database backend (e.g., 'sqlite:///mlflow.db') to take advantage of the latest MLflow features. See https://github.com/mlflow/mlflow/issues/18534 for more details and migration guidance. For migrating existing data, https://github.com/mlflow/mlflow-export-import can be used.\n",
      "  return FileStore(store_uri, store_uri)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 pruned\n",
      "Cleaning up Trial 20...\n",
      "Trial 20 cleanup complete\n",
      "[I 2026-01-09 18:58:51,414] Trial 20 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=175` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/cf5eec15ac1b4a0fa529b5b9e19a5906/checkpoints/trial_21_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/cf5eec15ac1b4a0fa529b5b9e19a5906/checkpoints/trial_21_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    103.91370391845703     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0194202661514282     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     6.479852199554443     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   103.91370391845703    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0194202661514282    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    6.479852199554443    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 19:46:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/09 19:47:08 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21: val_total_loss=4.4397, epochs=175\n",
      "Cleaning up Trial 21...\n",
      "Trial 21 cleanup complete\n",
      "[I 2026-01-09 19:47:19,277] Trial 21 finished with value: 4.439688205718994 and parameters: {'batch_size': 16, 'learning_rate': 0.0008940980313893668, 'num_epochs': 175, 'prob_horizontal_flip': 0.24629967018152077, 'prob_color_jitter': 0.37539010017857066, 'weight_decay': 0.0005589662060485111}. Best is trial 11 with value: 3.7052252292633057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=167` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/448ed14f63864994b65a6f6894e2dbd7/checkpoints/trial_22_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/448ed14f63864994b65a6f6894e2dbd7/checkpoints/trial_22_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.68146514892578     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6726418137550354     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.714705944061279     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.68146514892578    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6726418137550354    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.714705944061279    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 20:31:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/09 20:31:20 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22: val_total_loss=3.8952, epochs=167\n",
      "Cleaning up Trial 22...\n",
      "Trial 22 cleanup complete\n",
      "[I 2026-01-09 20:31:21,233] Trial 22 finished with value: 3.895165205001831 and parameters: {'batch_size': 16, 'learning_rate': 0.0009966118172869117, 'num_epochs': 167, 'prob_horizontal_flip': 0.32028463493777504, 'prob_color_jitter': 0.28041954423116344, 'weight_decay': 5.470661138069023e-05}. Best is trial 11 with value: 3.7052252292633057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=166` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/1e93a663989d475c89861090d164c599/checkpoints/trial_23_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/1e93a663989d475c89861090d164c599/checkpoints/trial_23_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    107.61917114257812     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7888700366020203     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.963535785675049     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   107.61917114257812    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7888700366020203    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.963535785675049    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 21:15:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/09 21:15:11 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23: val_total_loss=4.1545, epochs=166\n",
      "Cleaning up Trial 23...\n",
      "Trial 23 cleanup complete\n",
      "[I 2026-01-09 21:15:12,737] Trial 23 finished with value: 4.154537677764893 and parameters: {'batch_size': 16, 'learning_rate': 0.000978951442184171, 'num_epochs': 166, 'prob_horizontal_flip': 0.36944522512102235, 'prob_color_jitter': 0.2821649623856717, 'weight_decay': 6.93904070589944e-05}. Best is trial 11 with value: 3.7052252292633057.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/57e0d36347ac49f4a15130f953d9bbbf/checkpoints/trial_24_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/57e0d36347ac49f4a15130f953d9bbbf/checkpoints/trial_24_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     96.35924530029297     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7419207096099854     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.248282432556152     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    96.35924530029297    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7419207096099854    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.248282432556152    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 22:01:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/09 22:02:10 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24: val_total_loss=3.6215, epochs=180\n",
      "Cleaning up Trial 24...\n",
      "Trial 24 cleanup complete\n",
      "[I 2026-01-09 22:02:11,516] Trial 24 finished with value: 3.6214706897735596 and parameters: {'batch_size': 16, 'learning_rate': 0.0009960602799646832, 'num_epochs': 180, 'prob_horizontal_flip': 0.1771289532628319, 'prob_color_jitter': 0.17846431343995997, 'weight_decay': 8.917874406155283e-05}. Best is trial 24 with value: 3.6214706897735596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 pruned\n",
      "Cleaning up Trial 25...\n",
      "Trial 25 cleanup complete\n",
      "[I 2026-01-09 22:39:30,351] Trial 25 pruned. Trial was pruned at epoch 139.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26 pruned\n",
      "Cleaning up Trial 26...\n",
      "Trial 26 cleanup complete\n",
      "[I 2026-01-09 23:13:28,375] Trial 26 pruned. Trial was pruned at epoch 131.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=178` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/ea7bde93c0254f98811d8ad26d92992e/checkpoints/trial_27_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/ea7bde93c0254f98811d8ad26d92992e/checkpoints/trial_27_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    100.01347351074219     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.707436203956604     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.867071151733398     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   100.01347351074219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.707436203956604    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.867071151733398    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 00:00:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 00:00:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 27: val_total_loss=4.1283, epochs=178\n",
      "Cleaning up Trial 27...\n",
      "Trial 27 cleanup complete\n",
      "[I 2026-01-10 00:00:50,978] Trial 27 finished with value: 4.128293991088867 and parameters: {'batch_size': 16, 'learning_rate': 0.0009052596092973867, 'num_epochs': 178, 'prob_horizontal_flip': 0.1707847055640338, 'prob_color_jitter': 0.3510305415167705, 'weight_decay': 0.0002938313206199857}. Best is trial 24 with value: 3.6214706897735596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28 pruned\n",
      "Cleaning up Trial 28...\n",
      "Trial 28 cleanup complete\n",
      "[I 2026-01-10 00:08:18,505] Trial 28 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29 pruned\n",
      "Cleaning up Trial 29...\n",
      "Trial 29 cleanup complete\n",
      "[I 2026-01-10 00:48:03,664] Trial 29 pruned. Trial was pruned at epoch 153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 pruned\n",
      "Cleaning up Trial 30...\n",
      "Trial 30 cleanup complete\n",
      "[I 2026-01-10 00:54:59,598] Trial 30 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31 pruned\n",
      "Cleaning up Trial 31...\n",
      "Trial 31 cleanup complete\n",
      "[I 2026-01-10 01:02:02,923] Trial 31 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=166` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/0d884e0170e24287bc775a61794e49b5/checkpoints/trial_32_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/0d884e0170e24287bc775a61794e49b5/checkpoints/trial_32_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     99.37944793701172     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6989076733589172     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.813786029815674     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.37944793701172    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6989076733589172    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.813786029815674    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 01:45:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 01:46:16 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32: val_total_loss=4.0885, epochs=166\n",
      "Cleaning up Trial 32...\n",
      "Trial 32 cleanup complete\n",
      "[I 2026-01-10 01:46:27,134] Trial 32 finished with value: 4.088510513305664 and parameters: {'batch_size': 16, 'learning_rate': 0.0009720496482901908, 'num_epochs': 166, 'prob_horizontal_flip': 0.32199034621216294, 'prob_color_jitter': 0.2713752760172621, 'weight_decay': 9.032988780576775e-05}. Best is trial 24 with value: 3.6214706897735596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/4e8b7c4057b0426e8b6776b3f37d30f0/checkpoints/trial_33_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/4e8b7c4057b0426e8b6776b3f37d30f0/checkpoints/trial_33_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    103.00639343261719     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.740563690662384     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.396304130554199     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   103.00639343261719    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.740563690662384    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.396304130554199    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 02:33:15 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 02:33:36 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 33: val_total_loss=3.8018, epochs=180\n",
      "Cleaning up Trial 33...\n",
      "Trial 33 cleanup complete\n",
      "[I 2026-01-10 02:33:37,318] Trial 33 finished with value: 3.8018081188201904 and parameters: {'batch_size': 16, 'learning_rate': 0.0009863422801335117, 'num_epochs': 180, 'prob_horizontal_flip': 0.39313881690764574, 'prob_color_jitter': 0.19578265580432694, 'weight_decay': 6.169390837414319e-05}. Best is trial 24 with value: 3.6214706897735596.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34 pruned\n",
      "Cleaning up Trial 34...\n",
      "Trial 34 cleanup complete\n",
      "[I 2026-01-10 03:12:51,885] Trial 34 pruned. Trial was pruned at epoch 149.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=190` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/3867e24e9bb24b558e98234a730b58f1/checkpoints/trial_35_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/3867e24e9bb24b558e98234a730b58f1/checkpoints/trial_35_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     99.81153106689453     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.723976194858551     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    5.1706132888793945     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    99.81153106689453    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.723976194858551    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   5.1706132888793945    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 04:01:59 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 04:02:39 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 35: val_total_loss=3.5391, epochs=190\n",
      "Cleaning up Trial 35...\n",
      "Trial 35 cleanup complete\n",
      "[I 2026-01-10 04:02:50,792] Trial 35 finished with value: 3.5391173362731934 and parameters: {'batch_size': 16, 'learning_rate': 0.0009977781538187882, 'num_epochs': 190, 'prob_horizontal_flip': 0.12634797628672573, 'prob_color_jitter': 0.2050232374847364, 'weight_decay': 0.0001927923823637686}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36 pruned\n",
      "Cleaning up Trial 36...\n",
      "Trial 36 cleanup complete\n",
      "[I 2026-01-10 04:10:10,058] Trial 36 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 37 pruned\n",
      "Cleaning up Trial 37...\n",
      "Trial 37 cleanup complete\n",
      "[I 2026-01-10 04:17:13,694] Trial 37 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 38 pruned\n",
      "Cleaning up Trial 38...\n",
      "Trial 38 cleanup complete\n",
      "[I 2026-01-10 04:44:48,152] Trial 38 pruned. Trial was pruned at epoch 107.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 39 pruned\n",
      "Cleaning up Trial 39...\n",
      "Trial 39 cleanup complete\n",
      "[I 2026-01-10 04:52:23,707] Trial 39 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 40 pruned\n",
      "Cleaning up Trial 40...\n",
      "Trial 40 cleanup complete\n",
      "[I 2026-01-10 04:59:37,996] Trial 40 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 41 pruned\n",
      "Cleaning up Trial 41...\n",
      "Trial 41 cleanup complete\n",
      "[I 2026-01-10 05:06:58,618] Trial 41 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=183` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/4ee86a59933c4c0f950f3d129e789b98/checkpoints/trial_42_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/4ee86a59933c4c0f950f3d129e789b98/checkpoints/trial_42_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    100.97996520996094     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6369226574897766     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.112097263336182     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   100.97996520996094    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6369226574897766    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.112097263336182    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 05:54:07 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 05:54:33 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 42: val_total_loss=3.6595, epochs=183\n",
      "Cleaning up Trial 42...\n",
      "Trial 42 cleanup complete\n",
      "[I 2026-01-10 05:54:44,822] Trial 42 finished with value: 3.6594743728637695 and parameters: {'batch_size': 16, 'learning_rate': 0.0009979756191052754, 'num_epochs': 183, 'prob_horizontal_flip': 0.5396350179939764, 'prob_color_jitter': 0.2030709635400906, 'weight_decay': 7.849870943665709e-05}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 43 pruned\n",
      "Cleaning up Trial 43...\n",
      "Trial 43 cleanup complete\n",
      "[I 2026-01-10 06:27:41,117] Trial 43 pruned. Trial was pruned at epoch 126.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 44 pruned\n",
      "Cleaning up Trial 44...\n",
      "Trial 44 cleanup complete\n",
      "[I 2026-01-10 06:52:11,274] Trial 44 pruned. Trial was pruned at epoch 90.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 45 pruned\n",
      "Cleaning up Trial 45...\n",
      "Trial 45 cleanup complete\n",
      "[I 2026-01-10 06:59:36,095] Trial 45 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=116` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/9c1cd25c77e3474c9794a9b24a31051d/checkpoints/trial_46_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/9c1cd25c77e3474c9794a9b24a31051d/checkpoints/trial_46_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    103.45477294921875     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.0069751739501953     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    10.008983612060547     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   103.45477294921875    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.0069751739501953    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   10.008983612060547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 07:30:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 07:31:06 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 46: val_total_loss=6.3803, epochs=116\n",
      "Cleaning up Trial 46...\n",
      "Trial 46 cleanup complete\n",
      "[I 2026-01-10 07:31:17,948] Trial 46 finished with value: 6.380321025848389 and parameters: {'batch_size': 16, 'learning_rate': 0.0009861784023782866, 'num_epochs': 116, 'prob_horizontal_flip': 0.483341466126198, 'prob_color_jitter': 0.2526376079019177, 'weight_decay': 3.1734420431069934e-05}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 pruned\n",
      "Cleaning up Trial 47...\n",
      "Trial 47 cleanup complete\n",
      "[I 2026-01-10 07:48:20,183] Trial 47 pruned. Trial was pruned at epoch 65.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 48 pruned\n",
      "Cleaning up Trial 48...\n",
      "Trial 48 cleanup complete\n",
      "[I 2026-01-10 08:05:29,914] Trial 48 pruned. Trial was pruned at epoch 65.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 49 pruned\n",
      "Cleaning up Trial 49...\n",
      "Trial 49 cleanup complete\n",
      "[I 2026-01-10 08:12:44,451] Trial 49 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 pruned\n",
      "Cleaning up Trial 50...\n",
      "Trial 50 cleanup complete\n",
      "[I 2026-01-10 08:20:06,098] Trial 50 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 51 pruned\n",
      "Cleaning up Trial 51...\n",
      "Trial 51 cleanup complete\n",
      "[I 2026-01-10 08:27:52,587] Trial 51 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=180` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/d399d68a4dcd493696e23d381d8e90a3/checkpoints/trial_52_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/d399d68a4dcd493696e23d381d8e90a3/checkpoints/trial_52_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     103.2524185180664     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7178905010223389     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.544280529022217     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    103.2524185180664    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7178905010223389    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.544280529022217    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 09:14:41 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 09:15:01 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 52: val_total_loss=3.8640, epochs=180\n",
      "Cleaning up Trial 52...\n",
      "Trial 52 cleanup complete\n",
      "[I 2026-01-10 09:15:12,526] Trial 52 finished with value: 3.863969326019287 and parameters: {'batch_size': 16, 'learning_rate': 0.0009563039191132835, 'num_epochs': 180, 'prob_horizontal_flip': 0.4737203099680404, 'prob_color_jitter': 0.17082414522250947, 'weight_decay': 5.4798721927357805e-05}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 53 pruned\n",
      "Cleaning up Trial 53...\n",
      "Trial 53 cleanup complete\n",
      "[I 2026-01-10 09:52:32,569] Trial 53 pruned. Trial was pruned at epoch 143.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 54 pruned\n",
      "Cleaning up Trial 54...\n",
      "Trial 54 cleanup complete\n",
      "[I 2026-01-10 09:59:56,159] Trial 54 pruned. Trial was pruned at epoch 27.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 pruned\n",
      "Cleaning up Trial 55...\n",
      "Trial 55 cleanup complete\n",
      "[I 2026-01-10 10:41:23,785] Trial 55 pruned. Trial was pruned at epoch 165.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=175` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/5a43649001c148d688659eec3074c96c/checkpoints/trial_56_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/5a43649001c148d688659eec3074c96c/checkpoints/trial_56_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     98.14286804199219     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7760732173919678     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.110870838165283     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    98.14286804199219    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7760732173919678    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.110870838165283    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 11:23:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 11:24:09 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56: val_total_loss=3.7029, epochs=175\n",
      "Cleaning up Trial 56...\n",
      "Trial 56 cleanup complete\n",
      "[I 2026-01-10 11:24:20,913] Trial 56 finished with value: 3.7028772830963135 and parameters: {'batch_size': 16, 'learning_rate': 0.0009990605563671333, 'num_epochs': 175, 'prob_horizontal_flip': 0.34422712253709103, 'prob_color_jitter': 0.2046540446814962, 'weight_decay': 0.0005694699189613413}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 57 pruned\n",
      "Cleaning up Trial 57...\n",
      "Trial 57 cleanup complete\n",
      "[I 2026-01-10 11:31:42,070] Trial 57 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=155` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/c572d56383484594b5136136035662f9/checkpoints/trial_58_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/c572d56383484594b5136136035662f9/checkpoints/trial_58_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    100.02971649169922     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7989264726638794     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    6.9228410720825195     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   100.02971649169922    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7989264726638794    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   6.9228410720825195    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 12:13:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 12:13:43 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 58: val_total_loss=4.3783, epochs=155\n",
      "Cleaning up Trial 58...\n",
      "Trial 58 cleanup complete\n",
      "[I 2026-01-10 12:13:54,568] Trial 58 finished with value: 4.37828254699707 and parameters: {'batch_size': 16, 'learning_rate': 0.0009578445024556969, 'num_epochs': 155, 'prob_horizontal_flip': 0.18643549756294128, 'prob_color_jitter': 0.2937928857499023, 'weight_decay': 0.0004794146983211422}. Best is trial 35 with value: 3.5391173362731934.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 59 pruned\n",
      "Cleaning up Trial 59...\n",
      "Trial 59 cleanup complete\n",
      "[I 2026-01-10 12:20:37,705] Trial 59 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 pruned\n",
      "Cleaning up Trial 60...\n",
      "Trial 60 cleanup complete\n",
      "[I 2026-01-10 12:28:23,445] Trial 60 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=188` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/3378cff79bb247d1a59e743e433c0a49/checkpoints/trial_61_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/3378cff79bb247d1a59e743e433c0a49/checkpoints/trial_61_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    100.39940643310547     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6728142499923706     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     4.959061622619629     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   100.39940643310547    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6728142499923706    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    4.959061622619629    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 13:24:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 13:24:34 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 61: val_total_loss=3.4357, epochs=188\n",
      "Cleaning up Trial 61...\n",
      "Trial 61 cleanup complete\n",
      "[I 2026-01-10 13:24:45,874] Trial 61 finished with value: 3.4356820583343506 and parameters: {'batch_size': 16, 'learning_rate': 0.0009961605530437595, 'num_epochs': 188, 'prob_horizontal_flip': 0.29193988326691955, 'prob_color_jitter': 0.687297844202467, 'weight_decay': 0.0004999404266451548}. Best is trial 61 with value: 3.4356820583343506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=187` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/083f5f72f3f84e1cabc44dfdd84caf60/checkpoints/trial_62_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/083f5f72f3f84e1cabc44dfdd84caf60/checkpoints/trial_62_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    101.90242004394531     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6148788928985596     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    4.9600629806518555     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   101.90242004394531    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6148788928985596    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   4.9600629806518555    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 14:19:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 14:20:07 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 62: val_total_loss=3.4576, epochs=187\n",
      "Cleaning up Trial 62...\n",
      "Trial 62 cleanup complete\n",
      "[I 2026-01-10 14:20:08,378] Trial 62 finished with value: 3.4576141834259033 and parameters: {'batch_size': 16, 'learning_rate': 0.0009983621065923394, 'num_epochs': 187, 'prob_horizontal_flip': 0.30068335955390957, 'prob_color_jitter': 0.6891041219819003, 'weight_decay': 0.0007647123013609647}. Best is trial 61 with value: 3.4356820583343506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_epochs=187` reached.\n",
      "Restoring states from the checkpoint path at ./mlruns/990889733283869451/a68a23967bfb43d19107816983e0b8f9/checkpoints/trial_63_best.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from the checkpoint at ./mlruns/990889733283869451/a68a23967bfb43d19107816983e0b8f9/checkpoints/trial_63_best.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_depth_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    101.33065795898438     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_seg_loss       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6702907085418701     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_total_loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.102290630340576     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_depth_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   101.33065795898438    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_seg_loss      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6702907085418701    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_total_loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.102290630340576    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/10 15:12:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/10 15:12:19 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 63: val_total_loss=3.5357, epochs=187\n",
      "Cleaning up Trial 63...\n",
      "Trial 63 cleanup complete\n",
      "[I 2026-01-10 15:12:20,241] Trial 63 finished with value: 3.5356688499450684 and parameters: {'batch_size': 16, 'learning_rate': 0.000998651971276629, 'num_epochs': 187, 'prob_horizontal_flip': 0.30105147766510115, 'prob_color_jitter': 0.6886450782255154, 'weight_decay': 0.000781610552444396}. Best is trial 61 with value: 3.4356820583343506.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 64 pruned\n",
      "Cleaning up Trial 64...\n",
      "Trial 64 cleanup complete\n",
      "[I 2026-01-10 15:18:53,764] Trial 64 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 pruned\n",
      "Cleaning up Trial 65...\n",
      "Trial 65 cleanup complete\n",
      "[I 2026-01-10 15:25:32,160] Trial 65 pruned. Trial was pruned at epoch 25.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 66 pruned\n",
      "Cleaning up Trial 66...\n",
      "Trial 66 cleanup complete\n",
      "[I 2026-01-10 15:40:22,180] Trial 66 pruned. Trial was pruned at epoch 59.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 67 pruned\n",
      "Cleaning up Trial 67...\n",
      "Trial 67 cleanup complete\n",
      "[I 2026-01-10 15:48:25,494] Trial 67 pruned. Trial was pruned at epoch 31.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 68 pruned\n",
      "Cleaning up Trial 68...\n",
      "Trial 68 cleanup complete\n",
      "[I 2026-01-10 15:55:28,738] Trial 68 pruned. Trial was pruned at epoch 27.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 69 pruned\n",
      "Cleaning up Trial 69...\n",
      "Trial 69 cleanup complete\n",
      "[I 2026-01-10 16:02:06,783] Trial 69 pruned. Trial was pruned at epoch 25.\n",
      "\n",
      "============================================================\n",
      "Optimization Complete!\n",
      "============================================================\n",
      "Best trial number: 61\n",
      "Best validation loss: 3.4357\n",
      "Best hyperparameters:\n",
      "  batch_size: 16\n",
      "  learning_rate: 0.0009961605530437595\n",
      "  num_epochs: 188\n",
      "  prob_horizontal_flip: 0.29193988326691955\n",
      "  prob_color_jitter: 0.687297844202467\n",
      "  weight_decay: 0.0004999404266451548\n",
      "\n",
      "Generating optimization visualizations...\n",
      "Optimization plots logged to MLflow\n"
     ]
    }
   ],
   "source": [
    "N_TRIALS = 50\n",
    "\n",
    "# Safety: end any active runs before starting\n",
    "mlflow.end_run()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Create parent MLflow run\n",
    "with mlflow.start_run(run_name=\"optuna_depth_distillation_and_semantic_seg\") as parent_run:\n",
    "    \n",
    "    # Log study configuration\n",
    "    mlflow.log_param(\"optimization_metric\", \"val_total_loss\")\n",
    "    mlflow.log_param(\"n_trials\", N_TRIALS)\n",
    "    mlflow.log_param(\"model_type\", \"Depth_Distillation_and_Semantic_Segmentation_UNet\")\n",
    "    mlflow.log_param(\"dataset\", \"CamVid\")\n",
    "    \n",
    "    # Create Optuna study\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"depth_distillation_and_semantic_segmentation_optimization\",\n",
    "        direction=\"minimize\",\n",
    "        sampler=optuna.samplers.TPESampler(seed=42),\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=15, n_warmup_steps=25),\n",
    "        storage=\"sqlite:///optuna_study_depth_and_seg_weighted.db\",  # Persist to database\n",
    "        load_if_exists=True  # Resume if interrupted\n",
    "    )\n",
    "    \n",
    "    # Run optimization\n",
    "    print(\"Starting Optuna optimization...\")\n",
    "    study.optimize(\n",
    "        objective,\n",
    "        n_trials=N_TRIALS,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    \n",
    "    # Log best trial information\n",
    "    best_trial = study.best_trial\n",
    "    mlflow.log_params({f\"best_{k}\": v for k, v in best_trial.params.items()})\n",
    "    mlflow.log_metric(\"best_val_total_loss\", best_trial.value)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Optimization Complete!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Best trial number: {best_trial.number}\")\n",
    "    print(f\"Best validation loss: {best_trial.value:.4f}\")\n",
    "    print(f\"Best hyperparameters:\")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Generate and log optimization visualizations\n",
    "    print(\"\\nGenerating optimization visualizations...\")\n",
    "    \n",
    "    try:\n",
    "        # Create plots directory\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        \n",
    "        # Plot optimization history\n",
    "        fig1 = viz.plot_optimization_history(study)\n",
    "        fig1.write_html(\"plots/optimization_history.html\")\n",
    "        mlflow.log_artifact(\"plots/optimization_history.html\", \"optimization_plots\")\n",
    "        \n",
    "        # Plot parameter importances\n",
    "        fig2 = viz.plot_param_importances(study)\n",
    "        fig2.write_html(\"plots/param_importances.html\")\n",
    "        mlflow.log_artifact(\"plots/param_importances.html\", \"optimization_plots\")\n",
    "        \n",
    "        # Plot parallel coordinate\n",
    "        fig3 = viz.plot_parallel_coordinate(study)\n",
    "        fig3.write_html(\"plots/parallel_coordinate.html\")\n",
    "        mlflow.log_artifact(\"plots/parallel_coordinate.html\", \"optimization_plots\")\n",
    "        \n",
    "        # Plot slice\n",
    "        fig4 = viz.plot_slice(study)\n",
    "        fig4.write_html(\"plots/slice_plot.html\")\n",
    "        mlflow.log_artifact(\"plots/slice_plot.html\", \"optimization_plots\")\n",
    "        \n",
    "        print(\"Optimization plots logged to MLflow\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not generate visualizations: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a51fd0-e97c-4049-ac2b-ad341e9e5d7e",
   "metadata": {},
   "source": [
    "# 6. Evaluate Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269179bb-4590-4735-9f10-27e0c3c7f695",
   "metadata": {},
   "source": [
    "## 6.1 Load Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12172d-18f6-4071-a276-d12067ac9f47",
   "metadata": {},
   "source": [
    "### 6.1.1 Identify Best Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e37b4-e10c-492f-acd9-7dfdb20378b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Set experiment name\n",
    "EXPERIMENT_NAME = \"depth_distillation_and_semantic_segmentation_optimization\"\n",
    "\n",
    "# Get experiment\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"Experiment '{EXPERIMENT_NAME}' not found!\")\n",
    "\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Search for best run\n",
    "all_runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"metrics.best_val_total_loss > 0\",\n",
    "    order_by=[\"metrics.best_val_total_loss ASC\"],\n",
    "    max_results=1\n",
    ")\n",
    "\n",
    "if len(all_runs) == 0:\n",
    "    raise ValueError(\"No runs found with best_val_total_loss metric!\")\n",
    "\n",
    "best_run = all_runs[0]\n",
    "best_run_id = best_run.info.run_id\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Best Run Found!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Run ID: {best_run_id}\")\n",
    "print(f\"Best Val Loss: {best_run.data.metrics.get('best_val_total_loss', 'N/A'):.4f}\")\n",
    "\n",
    "try:\n",
    "    # Download artifacts directory\n",
    "    artifacts_path = client.download_artifacts(best_run_id, \"\")\n",
    "    print(f\"\\nDownloaded artifacts to: {artifacts_path}\")\n",
    "    \n",
    "    # Look for ckpt model in checkpoints\n",
    "    checkpoints_dir = os.path.join(artifacts_path, \"checkpoints\")\n",
    "    \n",
    "    if os.path.exists(checkpoints_dir):\n",
    "        # Find ckpt file\n",
    "        trial_number = best_run.data.params.get('trial_number', '0')\n",
    "        ckpt_files = [f for f in os.listdir(checkpoints_dir) \n",
    "                       if f.endswith('.ckpt')]\n",
    "        \n",
    "        if ckpt_files:\n",
    "            best_checkpoint_path = os.path.join(checkpoints_dir, ckpt_files[0])\n",
    "            print(f\"Loading model from: {best_checkpoint_path}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"No ckpt files found in {checkpoints_dir}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"checkpoints directory not found at {artifacts_path}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model from artifacts: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9238626a-1cf7-4843-ab24-a1a8d9e18ec7",
   "metadata": {},
   "source": [
    "### 6.1.2 Evaluate over Validation Set\n",
    "We load and test the model over validation set to assure everithing is right and we get the same \"best_val_loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f847a-b1ac-43c0-ba06-16cad861eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters from MLflow - FIXED\n",
    "best_params = {\n",
    "    'encoder_name': best_run.data.params['encoder_name'],\n",
    "    'encoder_weights': best_run.data.params['encoder_weights'],\n",
    "    'learning_rate': float(best_run.data.params['learning_rate']),\n",
    "    'weight_decay': float(best_run.data.params['weight_decay']),\n",
    "    'batch_size': int(best_run.data.params['batch_size'])\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create test data module\n",
    "test_data_module = DataModule(\n",
    "    train_img_dir=TRAIN_IMG_DIR,\n",
    "    train_depth_dir=TRAIN_DEPTH_DIR,\n",
    "    train_seg_dir=TRAIN_SEG_DIR,\n",
    "    val_img_dir=VAL_IMG_DIR,\n",
    "    val_depth_dir=VAL_DEPTH_DIR,\n",
    "    val_seg_dir=VAL_SEG_DIR,\n",
    "    test_img_dir=VAL_IMG_DIR, # We use val split\n",
    "    test_depth_dir=VAL_DEPTH_DIR, # We use val split\n",
    "    test_seg_dir=VAL_SEG_DIR, # We use val split\n",
    "    batch_size=best_params['batch_size'],\n",
    "    num_workers=2,\n",
    "    prob=None\n",
    ")\n",
    "test_data_module.setup()\n",
    "\n",
    "# Create the model with best architecture\n",
    "student = MultiTaskUnet(\n",
    "    num_classes=test_data_module.train_dataset.num_classes,\n",
    "    encoder_name=best_params['encoder_name'],\n",
    "    encoder_weights=best_params['encoder_weights'],\n",
    ")\n",
    "\n",
    "# Create Lightning module\n",
    "lightning_module = DepthSegDistillationModule(\n",
    "    student_model=student,\n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lightning_module.load_state_dict(checkpoint['state_dict'])\n",
    "lightning_module.eval()\n",
    "\n",
    "print(\"\\nBest model loaded successfully!\")\n",
    "\n",
    "# Create trainer for testing\n",
    "test_trainer = pl.Trainer(\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    logger=False\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Best Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_results = test_trainer.test(lightning_module, test_data_module)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in test_results[0].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d2d4e-b085-4a95-a9b1-7671933f9f0e",
   "metadata": {},
   "source": [
    "Perfect. We got the same loss, so the model was found and loaded correctly.\n",
    "Now, lets evaluate over the Test split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb78e3-c9c3-4c12-bd1c-591126258134",
   "metadata": {},
   "source": [
    "### 6.1.3 Evaluate over Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488df58a-cfc5-484d-9f35-43efd3136115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best hyperparameters from MLflow - FIXED\n",
    "best_params = {\n",
    "    'encoder_name': best_run.data.params['encoder_name'],\n",
    "    'encoder_weights': best_run.data.params['encoder_weights'],\n",
    "    'learning_rate': float(best_run.data.params['learning_rate']),\n",
    "    'weight_decay': float(best_run.data.params['weight_decay']),\n",
    "    'batch_size': int(best_run.data.params['batch_size'])\n",
    "}\n",
    "\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Create test data module\n",
    "test_data_module = DataModule(\n",
    "    train_img_dir=TRAIN_IMG_DIR,\n",
    "    train_depth_dir=TRAIN_DEPTH_DIR,\n",
    "    train_seg_dir=TRAIN_SEG_DIR,\n",
    "    val_img_dir=VAL_IMG_DIR,\n",
    "    val_depth_dir=VAL_DEPTH_DIR,\n",
    "    val_seg_dir=VAL_SEG_DIR,\n",
    "    test_img_dir=TEST_IMG_DIR,\n",
    "    test_depth_dir=TEST_DEPTH_DIR,\n",
    "    test_seg_dir=TEST_SEG_DIR,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    num_workers=2,\n",
    "    prob=None\n",
    ")\n",
    "test_data_module.setup()\n",
    "\n",
    "# Create the model with best architecture\n",
    "student = MultiTaskUnet(\n",
    "    num_classes=test_data_module.train_dataset.num_classes,\n",
    "    encoder_name=best_params['encoder_name'],\n",
    "    encoder_weights=best_params['encoder_weights'],\n",
    ")\n",
    "\n",
    "# Create Lightning module\n",
    "lightning_module = DepthSegDistillationModule(\n",
    "    student_model=student,\n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay']\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lightning_module.load_state_dict(checkpoint['state_dict'])\n",
    "lightning_module.eval()\n",
    "\n",
    "print(\"\\nBest model loaded successfully!\")\n",
    "\n",
    "# Create trainer for testing\n",
    "test_trainer = pl.Trainer(\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    logger=False\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Testing Best Model...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_results = test_trainer.test(lightning_module, test_data_module)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\"*60)\n",
    "for key, value in test_results[0].items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7eb5fd-0ef2-46ad-9755-d5341de88e42",
   "metadata": {},
   "source": [
    "## 6.2 Visualize Test Predictions\n",
    "Here we will see depth predictions of some random Test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ec084-c044-49aa-ba80-4392a4651a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, num_samples=5, seed=42, title_prefix=\"Test\"):\n",
    "    \"\"\"Visualize student predictions vs teacher depth maps and segmentation\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    random.seed(seed)\n",
    "    offset = random.randrange(0, len(dataset) - num_samples)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(min(num_samples, len(dataset))):\n",
    "            # Create figure with gridspec\n",
    "            fig = plt.figure(figsize=(15, 10))\n",
    "            gs = gridspec.GridSpec(2, 3, figure=fig, hspace=0.3, wspace=0.3)\n",
    "            \n",
    "            image, teacher_depth, seg_mask_gt = dataset[offset + i]\n",
    "            \n",
    "            # Get student predictions\n",
    "            student_depth_pred, student_seg_pred = model(image.unsqueeze(0).to(device))\n",
    "            student_depth_pred = student_depth_pred.squeeze().cpu().numpy()\n",
    "            student_seg_pred = torch.argmax(student_seg_pred, dim=1).squeeze().cpu().numpy()\n",
    "            \n",
    "            # Denormalize image for visualization\n",
    "            img_display = image.clone()\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "            img_display = img_display * std + mean\n",
    "            img_display = torch.clamp(img_display, 0, 1)\n",
    "            \n",
    "            # [0, 0] and [1, 0]: Original Image (spans 2 rows)\n",
    "            ax_img = fig.add_subplot(gs[:, 0])\n",
    "            ax_img.imshow(img_display.permute(1, 2, 0))\n",
    "            ax_img.set_title(f'{title_prefix} Sample {i+1}: Input Image', fontsize=12, fontweight='bold')\n",
    "            ax_img.axis('off')\n",
    "            \n",
    "            # [0, 1]: Teacher Depth Map\n",
    "            ax_teacher_depth = fig.add_subplot(gs[0, 1])\n",
    "            im1 = ax_teacher_depth.imshow(teacher_depth.numpy(), cmap='Spectral')\n",
    "            ax_teacher_depth.set_title('Teacher Depth (DA3)', fontsize=12, fontweight='bold')\n",
    "            ax_teacher_depth.axis('off')\n",
    "            plt.colorbar(im1, ax=ax_teacher_depth, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # [0, 2]: Ground Truth Semantic Segmentation\n",
    "            ax_seg_gt = fig.add_subplot(gs[0, 2])\n",
    "            im2 = ax_seg_gt.imshow(seg_mask_gt.numpy(), cmap='tab20')\n",
    "            ax_seg_gt.set_title('GT Semantic Segmentation', fontsize=12, fontweight='bold')\n",
    "            ax_seg_gt.axis('off')\n",
    "            plt.colorbar(im2, ax=ax_seg_gt, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # [1, 1]: Student Predicted Depth Map\n",
    "            ax_student_depth = fig.add_subplot(gs[1, 1])\n",
    "            im3 = ax_student_depth.imshow(student_depth_pred, cmap='Spectral')\n",
    "            ax_student_depth.set_title('Student Depth (U-Net ResNet18)', fontsize=12, fontweight='bold')\n",
    "            ax_student_depth.axis('off')\n",
    "            plt.colorbar(im3, ax=ax_student_depth, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # [1, 2]: Student Predicted Semantic Segmentation\n",
    "            ax_student_seg = fig.add_subplot(gs[1, 2])\n",
    "            im4 = ax_student_seg.imshow(student_seg_pred, cmap='tab20')\n",
    "            ax_student_seg.set_title('Student Semantic Segmentation', fontsize=12, fontweight='bold')\n",
    "            ax_student_seg.axis('off')\n",
    "            plt.colorbar(im4, ax=ax_student_seg, fraction=0.046, pad=0.04)\n",
    "            \n",
    "            plt.savefig(f'{title_prefix.lower()}_predictions_sample_{i+1}.png', dpi=150, bbox_inches='tight')\n",
    "            plt.show()\n",
    "\n",
    "print(\"Visualizing predictions on TEST set:\")\n",
    "test_dataset = DepthDistillationDataset(\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    depth_dir=TEST_DEPTH_DIR,\n",
    "    seg_dir=TEST_SEG_DIR,\n",
    "    num_classes=32,\n",
    "    is_train=False\n",
    ")\n",
    "visualize_predictions(lightning_module.student, test_dataset, num_samples=5, title_prefix=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb14595-33c1-4f6d-8ff8-73953117ac81",
   "metadata": {},
   "source": [
    "## 6.3 Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a30c4e-3459-4dca-a1ea-2e641b197c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, dataloader, split_name=\"Test\"):\n",
    "    \"\"\"Calculate depth estimation metrics\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_mse = 0\n",
    "    total_mae = 0\n",
    "    total_abs_rel = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, teacher_depth, seg_mask_gt in dataloader:\n",
    "            images = images.to(device)\n",
    "            teacher_depth = teacher_depth.to(device)\n",
    "            seg_mask_gt = seg_mask_gt.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            student_depth_pred, student_seg_pred = model(images)\n",
    "            student_depth_pred = student_depth_pred.squeeze(1)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = F.mse_loss(student_depth_pred, teacher_depth)\n",
    "            mae = F.l1_loss(student_depth_pred, teacher_depth)\n",
    "            abs_rel = torch.mean(torch.abs(student_depth_pred - teacher_depth) / (teacher_depth + 1e-8))\n",
    "            \n",
    "            total_mse += mse.item() * images.size(0)\n",
    "            total_mae += mae.item() * images.size(0)\n",
    "            total_abs_rel += abs_rel.item() * images.size(0)\n",
    "            num_samples += images.size(0)\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': total_mse / num_samples,\n",
    "        'MAE': total_mae / num_samples,\n",
    "        'RMSE': np.sqrt(total_mse / num_samples),\n",
    "        'Abs Rel': total_abs_rel / num_samples\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{split_name} Set Metrics:\")\n",
    "    print(\"=\" * 40)\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"  {metric_name:12s}: {value:.4f}\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Create data module\n",
    "test_data_module = DataModule(\n",
    "    train_img_dir=TRAIN_IMG_DIR,\n",
    "    train_depth_dir=TRAIN_DEPTH_DIR,\n",
    "    train_seg_dir=TRAIN_SEG_DIR,\n",
    "    val_img_dir=VAL_IMG_DIR,\n",
    "    val_depth_dir=VAL_DEPTH_DIR,\n",
    "    val_seg_dir=VAL_SEG_DIR,\n",
    "    test_img_dir=TEST_IMG_DIR,\n",
    "    test_depth_dir=TEST_DEPTH_DIR,\n",
    "    test_seg_dir=TEST_SEG_DIR,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    num_workers=2,\n",
    "    prob=None\n",
    ")\n",
    "test_data_module.setup(stage='test')\n",
    "\n",
    "# Calculate metrics on TEST set\n",
    "test_loader = test_data_module.test_dataloader()\n",
    "test_metrics = calculate_metrics(lightning_module.student, test_loader, split_name=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189361ab-2d97-4376-8297-adb424ac7b4d",
   "metadata": {},
   "source": [
    "## 6.4 Test Set Detailed Analysis\n",
    "We will compute the MSE and MAE error of the selected Test samples and visualize the worst performing and best performing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a534e2b-c202-41f2-85c2-77f462e6658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_test_analysis(model, dataset, num_samples=10):\n",
    "    \"\"\"Perform detailed analysis on test samples\"\"\"\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    worst_sample_idx = -1\n",
    "    best_sample_idx = -1\n",
    "    best_mse = np.inf\n",
    "    worst_mse = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(min(num_samples, len(dataset))):\n",
    "            image, teacher_depth, seg_mask_gt = dataset[i]\n",
    "            \n",
    "            # Get prediction\n",
    "            student_depth_pred, student_seg_pred = model(image.unsqueeze(0).to(device))\n",
    "            student_depth_pred = student_depth_pred.squeeze().cpu()\n",
    "            \n",
    "            # Calculate per-sample error\n",
    "            mse = F.mse_loss(student_depth_pred, teacher_depth).item()\n",
    "            mae = F.l1_loss(student_depth_pred, teacher_depth).item()\n",
    "            \n",
    "            errors.append({\n",
    "                'sample_idx': i,\n",
    "                'MSE': mse,\n",
    "                'MAE': mae\n",
    "            })\n",
    "\n",
    "            # Track worst and best samples taking into account MSE value\n",
    "            if mse > worst_mse:\n",
    "                worst_mse = mse\n",
    "                worst_sample_idx = i\n",
    "                \n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_sample_idx = i\n",
    "    \n",
    "    # Print per-sample results\n",
    "    print(\"\\nPer-Sample Test Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    for error in errors:\n",
    "        print(f\"Sample {error['sample_idx']:3d}: MSE={error['MSE']:.4f}, MAE={error['MAE']:.4f}\")\n",
    "    \n",
    "    # Statistical summary\n",
    "    mse_values = [e['MSE'] for e in errors]\n",
    "    mae_values = [e['MAE'] for e in errors]\n",
    "    \n",
    "    print(\"\\nStatistical Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"MSE - Mean: {np.mean(mse_values):.4f}, Std: {np.std(mse_values):.4f}\")\n",
    "    print(f\"MAE - Mean: {np.mean(mae_values):.4f}, Std: {np.std(mae_values):.4f}\")\n",
    "\n",
    "    return worst_sample_idx, best_sample_idx\n",
    "\n",
    "def visualize_edge_predictions(model, dataset, worst_sample_idx, best_sample_idx):\n",
    "    \"\"\"Visualize student predictions vs teacher depth maps\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Worst predicted sample\n",
    "        image, teacher_depth, seg_mask_gt = dataset[worst_sample_idx]\n",
    "            \n",
    "        # Get student prediction\n",
    "        student_depth_pred, student_seg_pred = model(image.unsqueeze(0).to(device))\n",
    "        student_pred = student_depth_pred.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        img_display = image.clone()\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img_display = img_display * std + mean\n",
    "        img_display = torch.clamp(img_display, 0, 1)\n",
    "        \n",
    "        # Plot\n",
    "        axes[0, 0].imshow(img_display.permute(1, 2, 0))\n",
    "        axes[0, 0].set_title(f'Worst predicted Test sample')\n",
    "        axes[0, 0].axis('off')\n",
    "        \n",
    "        axes[0, 1].imshow(teacher_depth.numpy(), cmap='Spectral')\n",
    "        axes[0, 1].set_title('Teacher Depth (DA3)')\n",
    "        axes[0, 1].axis('off')\n",
    "        \n",
    "        axes[0, 2].imshow(student_pred, cmap='Spectral')\n",
    "        axes[0, 2].set_title('Student Depth (U-Net ResNet18)')\n",
    "        axes[0, 2].axis('off')\n",
    "\n",
    "        # Best predicted sample\n",
    "        image, teacher_depth, seg_mask_gt = dataset[best_sample_idx]\n",
    "            \n",
    "        # Get student prediction\n",
    "        student_depth_pred, student_seg_pred = model(image.unsqueeze(0).to(device))\n",
    "        student_pred = student_depth_pred.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        img_display = image.clone()\n",
    "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img_display = img_display * std + mean\n",
    "        img_display = torch.clamp(img_display, 0, 1)\n",
    "        \n",
    "        # Plot\n",
    "        axes[1, 0].imshow(img_display.permute(1, 2, 0))\n",
    "        axes[1, 0].set_title(f'Best predicted Test sample')\n",
    "        axes[1, 0].axis('off')\n",
    "        \n",
    "        axes[1, 1].imshow(teacher_depth.numpy(), cmap='Spectral')\n",
    "        axes[1, 1].set_title('Teacher Depth (DA3)')\n",
    "        axes[1, 1].axis('off')\n",
    "        \n",
    "        axes[1, 2].imshow(student_pred, cmap='Spectral')\n",
    "        axes[1, 2].set_title('Student Depth (U-Net ResNet18)')\n",
    "        axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'worst_best_test_depth_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Run detailed analysis\n",
    "test_dataset = DepthDistillationDataset(\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    depth_dir=TEST_DEPTH_DIR,\n",
    "    seg_dir=TEST_SEG_DIR,\n",
    ")\n",
    "\n",
    "worst_sample_idx, best_sample_idx = detailed_test_analysis(lightning_module.student, test_dataset, num_samples=len(test_dataset))\n",
    "print(f\"Worst predicted sample found at image #{worst_sample_idx}\")\n",
    "print(f\"Best predicted sample found at image #{best_sample_idx}\")\n",
    "print()\n",
    "\n",
    "visualize_edge_predictions(lightning_module.student, test_dataset, worst_sample_idx, best_sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78117667-9286-422f-ad88-41cc56a1f792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
